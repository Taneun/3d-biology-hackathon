{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53537e82",
   "metadata": {},
   "source": [
    "# NESDB Combined Database Notebook\n",
    "This notebook fetches the NES pattern HTML, parses it to extract NESdb annotations, merges with the original CRM1 CSV to include protein names, full sequences, and headers, and saves a combined database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4ce29",
   "metadata": {},
   "source": [
    "## 1. Download the NES pattern HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b716bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download the NES pattern page\n",
    "url = \"http://prodata.swmed.edu/nes_pattern_location/\"\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()\n",
    "\n",
    "# Save HTML locally\n",
    "with open(\"data/nes_pattern_location.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(resp.text)\n",
    "\n",
    "print(\"Downloaded NES pattern HTML to nes_pattern_location.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c4579",
   "metadata": {},
   "source": [
    "## 2. Parse HTML and build annotation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "8c8920cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:14:26.066937Z",
     "start_time": "2025-06-18T11:14:20.803229Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read and parse the saved HTML\n",
    "with open(\"data/nes_pattern_location.html\", encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "# Load the main table\n",
    "html_df = pd.read_html(str(soup))[0]\n",
    "html_df.columns = html_df.columns.str.strip()\n",
    "\n",
    "# Extract numeric NESdb_ID (nullable Int64)\n",
    "ids = html_df['refDB'].str.extract(r'NESdb:(\\d+)')[0]\n",
    "html_df['NESdb_ID'] = ids.astype('Int64')\n",
    "\n",
    "# Extract UniProt ID column from HTML (adjust column name as needed)\n",
    "if 'uniprotID' in html_df.columns:\n",
    "    html_df['uniprotID'] = html_df['uniprotID']\n",
    "elif 'UniProt ID' in html_df.columns:\n",
    "    html_df['uniprotID'] = html_df['UniProt ID']\n",
    "else:\n",
    "    html_df['uniprotID'] = pd.NA  # placeholder if missing\n",
    "\n",
    "# Extract true peptide sequence (letters only)\n",
    "html_df['true_sequence'] = html_df['sequence'].str.extract(r'^([A-Z]+)')[0]\n",
    "\n",
    "# Extract start and compute end position\n",
    "html_df['start'] = html_df['start#'].astype(int)\n",
    "html_df['end'] = html_df['start'] + html_df['true_sequence'].str.len() - 1\n",
    "\n",
    "# Drop rows without a valid NESdb_ID\n",
    "html_df = html_df.dropna(subset=['NESdb_ID'])\n",
    "\n",
    "# Build the annotation DataFrame\n",
    "annotation_df = (\n",
    "    html_df[['NESdb_ID', 'uniprotID', 'true_sequence', 'start', 'end']]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "print(f\"Prepared annotation for {len(annotation_df)} unique NESdb entries.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shay3\\AppData\\Local\\Temp\\ipykernel_19064\\2899887163.py:10: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  html_df = pd.read_html(str(soup))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared annotation for 381 unique NESdb entries.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "e850fea2",
   "metadata": {},
   "source": [
    "## 3. Load original CRM1 CSV and extract metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "bdfdbb77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:14:29.548197Z",
     "start_time": "2025-06-18T11:14:29.466640Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV with full protein sequences and headers\n",
    "df = pd.read_csv(\"data/NesDB_all_CRM1_with_peptides_train.csv\")\n",
    "\n",
    "# Extract NESdb_ID from the 'ID' column\n",
    "df['NESdb_ID'] = (\n",
    "    df['ID']\n",
    "      .str.extract(r'NES ID:\\s*(\\d+)')[0]\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Keep only the metadata columns and rename 'Full Name' to 'name'\n",
    "df_meta = df[['NESdb_ID', 'ID', 'Sequence', 'Fasta Header']].rename(columns={'ID': 'name'})\n",
    "\n",
    "print(f\"Loaded original CSV metadata for {len(df_meta)} entries.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded original CSV metadata for 351 entries.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "44c36a42",
   "metadata": {},
   "source": [
    "## 4. Merge annotation with metadata and save"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b8943f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T11:14:39.124591Z",
     "start_time": "2025-06-18T11:14:39.083351Z"
    }
   },
   "source": [
    "# Merge annotation_df with df_meta on NESdb_ID\n",
    "combined_db = (\n",
    "    annotation_df\n",
    "    .merge(df_meta, on='NESdb_ID', how='left')\n",
    ")\n",
    "\n",
    "# Reorder columns to:\n",
    "# NESdb_ID, uniprotID, name, true_sequence, start, end, Sequence, Fasta Header\n",
    "combined_db = combined_db[[\n",
    "    'NESdb_ID',\n",
    "    'uniprotID',\n",
    "    'name',\n",
    "    'true_sequence',\n",
    "    'start',\n",
    "    'end',\n",
    "    'Sequence',\n",
    "    'Fasta Header'\n",
    "]]\n",
    "\n",
    "# remove duplicated rows and rows with missing values\n",
    "combined_db = combined_db.drop_duplicates(keep='first')\n",
    "combined_db = combined_db.dropna()\n",
    "\n",
    "# Save the combined database\n",
    "combined_db.to_csv(\"NESDB_combined_database.csv\", index=False)\n",
    "\n",
    "print(f\"Saved combined database with {len(combined_db)} rows to NESDB_combined_database.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined database with 560 rows to NESDB_combined_database.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
